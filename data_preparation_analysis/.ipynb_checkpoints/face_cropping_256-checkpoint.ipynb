{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07186b04",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup-and-Overview\" data-toc-modified-id=\"Setup-and-Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup and Overview</a></span></li><li><span><a href=\"#Crop-Faces-from-Images\" data-toc-modified-id=\"Crop-Faces-from-Images-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Crop Faces from Images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-faulty-images\" data-toc-modified-id=\"Remove-faulty-images-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Remove faulty images</a></span></li></ul></li><li><span><a href=\"#Train-Test-Split-and-Save-Images\" data-toc-modified-id=\"Train-Test-Split-and-Save-Images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train Test Split and Save Images</a></span></li><li><span><a href=\"#Export-data-and-labels-as-arrays\" data-toc-modified-id=\"Export-data-and-labels-as-arrays-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Export data and labels as arrays</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Training Data</a></span></li><li><span><a href=\"#Test-Data\" data-toc-modified-id=\"Test-Data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Test Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd17bc6",
   "metadata": {},
   "source": [
    "# Setup and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5ee9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load requirements\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from face_detector import YoloDetector\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import asarray, load, savez_compressed\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46020d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60563"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set base path and load attributes\n",
    "\n",
    "base_path = \"path/\"\n",
    "\n",
    "df = pd.read_csv(base_path + \"labels_inmates_complete_scored.csv\")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8884a832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>hair</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>bmi_class</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00147</td>\n",
       "      <td>83.914520</td>\n",
       "      <td>170.18</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>34</td>\n",
       "      <td>28.974775</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00220</td>\n",
       "      <td>70.306760</td>\n",
       "      <td>185.42</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>59</td>\n",
       "      <td>20.449558</td>\n",
       "      <td>Healthy weight</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00360</td>\n",
       "      <td>75.749864</td>\n",
       "      <td>175.26</td>\n",
       "      <td>1</td>\n",
       "      <td>Gray or Partially Gray</td>\n",
       "      <td>White</td>\n",
       "      <td>42</td>\n",
       "      <td>24.661316</td>\n",
       "      <td>Healthy weight</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00367</td>\n",
       "      <td>111.130040</td>\n",
       "      <td>182.88</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>63</td>\n",
       "      <td>33.227605</td>\n",
       "      <td>Class 1 Obesity</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01054</td>\n",
       "      <td>75.296272</td>\n",
       "      <td>170.18</td>\n",
       "      <td>1</td>\n",
       "      <td>Salt and Pepper</td>\n",
       "      <td>Black</td>\n",
       "      <td>34</td>\n",
       "      <td>25.998988</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      weight  height  sex                    hair   race  age  \\\n",
       "0  A00147   83.914520  170.18    1                   Brown  White   34   \n",
       "1  A00220   70.306760  185.42    1                   Black  Black   59   \n",
       "2  A00360   75.749864  175.26    1  Gray or Partially Gray  White   42   \n",
       "3  A00367  111.130040  182.88    1                   Black  Black   63   \n",
       "4  A01054   75.296272  170.18    1         Salt and Pepper  Black   34   \n",
       "\n",
       "         BMI        bmi_class  health_score  \n",
       "0  28.974775       Overweight           479  \n",
       "1  20.449558   Healthy weight           501  \n",
       "2  24.661316   Healthy weight           511  \n",
       "3  33.227605  Class 1 Obesity           449  \n",
       "4  25.998988       Overweight           494  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b9710",
   "metadata": {},
   "source": [
    "# Crop Faces from Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b5af9",
   "metadata": {},
   "source": [
    "Do not run this part, if the arrays already exist!! -> it takes >100min for 60'000 images!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712bfb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60563"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list with all image ids in the dataframe\n",
    "\n",
    "idx = df.id.values.tolist()\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd6fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A00147', 'A00220', 'A00360', 'A00367', 'A01054']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the frist five\n",
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model to crop faces (may need to run this cell twice until no warning is shown)\n",
    "\n",
    "model = YoloDetector(device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16109c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to detect faulty images and return a list with their id\n",
    "\n",
    "\n",
    "# function to check if a face is in the image\n",
    "def crop_face(img_idx):\n",
    "    \n",
    "    # suppress DeprecationWarning messages to avoid printing logs\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*--img-size.*\")\n",
    "    \n",
    "    # create lists as output\n",
    "    images = list()\n",
    "    no_face = list()\n",
    "    img_ids = list ()\n",
    "    for i, image_id in enumerate(img_idx):\n",
    "        \n",
    "        # Read the input image\n",
    "        orgimg = np.array(Image.open(base_path + \"front/front/\" + image_id + \".jpg\"))\n",
    "\n",
    "        try:  \n",
    "            bboxes = model.predict(orgimg)[0]\n",
    "            # extract bounding box\n",
    "            x1 = bboxes[0][0][0]\n",
    "            y1 = bboxes[0][0][1]\n",
    "            x2 = bboxes[0][0][2]\n",
    "            y2 = bboxes[0][0][3]\n",
    "            # crop image\n",
    "            c_img = orgimg[y1:y2, x1:x2]\n",
    "            # rezise image to 256 * 256           \n",
    "            c_img = cv2.resize(c_img, (256, 256))\n",
    "            # create list with succesfully cropped images\n",
    "            img_ids.append(image_id)\n",
    "            # add image to list to later export all as one np.array\n",
    "            images.append(c_img)\n",
    "\n",
    "        except IndexError:\n",
    "            print(\"Not Face detected, check image! ID: \" + str(image_id))\n",
    "            no_face.append(image_id)\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Error with Image, check image! ID: \" + str(image_id))\n",
    "            no_face.append(image_id)\n",
    "        # print progress every 100 images\n",
    "        if i % 100 == 0:\n",
    "            print(i , \"/\" ,len(img_idx))\n",
    "            \n",
    "    # reset warning filters\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    # return all list created in the function (images are returned as np.array)    \n",
    "    return asarray(images),img_ids, no_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the images -> only a list of image ids is required as input\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "faces, img_ids, no_face = crop_face(idx)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "print(f\"Elapsed time: {int(minutes)} minutes and {round(seconds, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c05f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save array with all faces\n",
    "\n",
    "savez_compressed(base_path + 'data_arrays/faces_256.npz', faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7063ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# check shape of first image\n",
    "\n",
    "for face in faces:\n",
    "    print(face.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9ddb5",
   "metadata": {},
   "source": [
    "## Remove faulty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90df0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before cleaning: 60563\n",
      "Size after cleaning: 59852\n"
     ]
    }
   ],
   "source": [
    "# remove data of faulty images from metadata\n",
    "\n",
    "print(\"Size before cleaning:\", len(df))\n",
    "\n",
    "for face_id in no_face:\n",
    "    df = df.drop(df[df['id'] == face_id].index)\n",
    "    \n",
    "print(\"Size after cleaning:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03266f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new df\n",
    "\n",
    "df.to_csv(base_path + 'labels/labels_inmates_complete_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab616990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59852, 256, 256, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print final shape of array with faces -> should be the same number as size after cleaning in the previous cell\n",
    "\n",
    "faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7bf42",
   "metadata": {},
   "source": [
    "# Train Test Split and Save Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c42f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (47881, 256, 256, 3)\n",
      "Train labels shape: (47881, 10)\n",
      "Test images shape: (11971, 256, 256, 3)\n",
      "Test labels shape: (11971, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>hair</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>bmi_class</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17444</th>\n",
       "      <td>M10305</td>\n",
       "      <td>108.862080</td>\n",
       "      <td>180.34</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>27</td>\n",
       "      <td>33.472835</td>\n",
       "      <td>Class 1 Obesity</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45399</th>\n",
       "      <td>R89181</td>\n",
       "      <td>87.543256</td>\n",
       "      <td>170.18</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>28</td>\n",
       "      <td>30.227739</td>\n",
       "      <td>Class 1 Obesity</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41862</th>\n",
       "      <td>R60277</td>\n",
       "      <td>111.130040</td>\n",
       "      <td>177.80</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>29</td>\n",
       "      <td>35.153450</td>\n",
       "      <td>Class 2 Obesity</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50047</th>\n",
       "      <td>X57499</td>\n",
       "      <td>90.718400</td>\n",
       "      <td>180.34</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>51</td>\n",
       "      <td>27.894029</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>K61421</td>\n",
       "      <td>77.110640</td>\n",
       "      <td>170.18</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>36</td>\n",
       "      <td>26.625469</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>B33552</td>\n",
       "      <td>70.760352</td>\n",
       "      <td>177.80</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>20</td>\n",
       "      <td>22.383421</td>\n",
       "      <td>Healthy weight</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58457</th>\n",
       "      <td>Y22831</td>\n",
       "      <td>78.471416</td>\n",
       "      <td>185.42</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>28</td>\n",
       "      <td>22.824346</td>\n",
       "      <td>Healthy weight</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30011</th>\n",
       "      <td>M55074</td>\n",
       "      <td>81.646560</td>\n",
       "      <td>175.26</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>20</td>\n",
       "      <td>26.581059</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42031</th>\n",
       "      <td>R61244</td>\n",
       "      <td>84.368112</td>\n",
       "      <td>172.72</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>24</td>\n",
       "      <td>28.280890</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56882</th>\n",
       "      <td>Y20696</td>\n",
       "      <td>58.966960</td>\n",
       "      <td>182.88</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>21</td>\n",
       "      <td>17.630974</td>\n",
       "      <td>Underweight</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11971 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      weight  height  sex   hair   race  age        BMI  \\\n",
       "17444  M10305  108.862080  180.34    1  Black  Black   27  33.472835   \n",
       "45399  R89181   87.543256  170.18    0  Brown  Black   28  30.227739   \n",
       "41862  R60277  111.130040  177.80    1  Black  Black   29  35.153450   \n",
       "50047  X57499   90.718400  180.34    1  Black  Black   51  27.894029   \n",
       "11383  K61421   77.110640  170.18    1  Black  Black   36  26.625469   \n",
       "...       ...         ...     ...  ...    ...    ...  ...        ...   \n",
       "3574   B33552   70.760352  177.80    1  Black  Black   20  22.383421   \n",
       "58457  Y22831   78.471416  185.42    1  Black  Black   28  22.824346   \n",
       "30011  M55074   81.646560  175.26    1  Black  White   20  26.581059   \n",
       "42031  R61244   84.368112  172.72    1  Black  Black   24  28.280890   \n",
       "56882  Y20696   58.966960  182.88    1  Brown  White   21  17.630974   \n",
       "\n",
       "             bmi_class  health_score  \n",
       "17444  Class 1 Obesity           455  \n",
       "45399  Class 1 Obesity           517  \n",
       "41862  Class 2 Obesity           445  \n",
       "50047       Overweight           497  \n",
       "11383       Overweight           493  \n",
       "...                ...           ...  \n",
       "3574    Healthy weight           497  \n",
       "58457   Healthy weight           512  \n",
       "30011       Overweight           481  \n",
       "42031       Overweight           474  \n",
       "56882      Underweight           424  \n",
       "\n",
       "[11971 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split for images and labels\n",
    "\n",
    "\n",
    "# create df with required labels\n",
    "y = df\n",
    "\n",
    "# Splitting the data into train and test sets with 80% for training and 20% for testing -> stratify for BMI and Sex\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(faces, y, test_size=0.2, random_state=123, stratify=y[['bmi_class','sex']])\n",
    "\n",
    "# Printing the shapes of the train and test data\n",
    "print('Train images shape:', train_images.shape)\n",
    "print('Train labels shape:', train_labels.shape)\n",
    "print('Test images shape:', test_images.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5a598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train and test labels as CSV\n",
    "\n",
    "train_labels.to_csv(base_path + 'labels/train_labels.csv', index = False)\n",
    "test_labels.to_csv(base_path + 'labels/test_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a656b0",
   "metadata": {},
   "source": [
    "# Export data and labels as arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad7e24a",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4302d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI training set:  (47881,)\n",
      "BMI Class training set:  (47881,)\n",
      "HS training set:  (47881,)\n"
     ]
    }
   ],
   "source": [
    "# create arrays for training labels\n",
    "bmi_train = train_labels['BMI'].values\n",
    "bmi_class_train = train_labels['bmi_class'].values\n",
    "hs_train = train_labels['health_score'].values\n",
    "\n",
    "\n",
    "print(\"BMI training set: \", bmi_train.shape)\n",
    "print(\"BMI Class training set: \", bmi_class_train.shape)\n",
    "print(\"HS training set: \", hs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f2fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train arrays \n",
    "savez_compressed(base_path + 'data_arrays/train_images.npz', train_images)\n",
    "savez_compressed(base_path + 'data_arrays/bmi_train.npz', bmi_train)\n",
    "savez_compressed(base_path + 'data_arrays/bmi_class_train.npz', bmi_class_train)\n",
    "savez_compressed(base_path + 'data_arrays/hs_train.npz', hs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af908ed",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78dc1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMI test set:  (11971,)\n",
      "BMI Class test set:  (11971,)\n",
      "HS test set:  (11971,)\n"
     ]
    }
   ],
   "source": [
    "# create arrays for test labels\n",
    "bmi_test = test_labels['BMI'].values\n",
    "bmi_class_test = test_labels['bmi_class'].values\n",
    "hs_test = test_labels['health_score'].values\n",
    "\n",
    "print(\"BMI test set: \", bmi_test.shape)\n",
    "print(\"BMI Class test set: \", bmi_class_test.shape)\n",
    "print(\"HS test set: \", hs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edab7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test arrays\n",
    "savez_compressed(base_path + 'data_arrays/test_images.npz', test_images)\n",
    "savez_compressed(base_path + 'data_arrays/bmi_test.npz', bmi_test)\n",
    "savez_compressed(base_path + 'data_arrays/bmi_class_test.npz', bmi_class_test)\n",
    "savez_compressed(base_path + 'data_arrays/hs_test.npz', hs_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloface",
   "language": "python",
   "name": "yoloface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
